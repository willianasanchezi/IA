{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7b11b5-edaa-4adb-ada4-1b5e24b923a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información Referencia\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb?hl=es-419#scrollTo=s3E6NFV-00Qt\n",
    "\"\"\"\n",
    "print(\"Información Referencia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a492d37-498a-4a97-8a2b-89c909a0a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270f1bcb-3ba4-4bf5-9b8e-f009fb829571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  face_landmarks_list = detection_result.face_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected faces to visualize.\n",
    "  for idx in range(len(face_landmarks_list)):\n",
    "    face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "    # Draw the face landmarks.\n",
    "    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    face_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "    ])\n",
    "\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp.solutions.drawing_styles\n",
    "          .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702ec418-898e-42b7-b535-9f926e0f1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
    "  # Extract the face blendshapes category names and scores.\n",
    "  face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
    "  face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
    "  # The blendshapes are ordered in decreasing score value.\n",
    "  face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(12, 12))\n",
    "  bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
    "  ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
    "  ax.invert_yaxis()\n",
    "\n",
    "  # Label each bar with values\n",
    "  for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
    "    plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
    "\n",
    "  ax.set_xlabel('Score')\n",
    "  ax.set_title(\"Face Blendshapes\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68f8a21-91dc-4327-b391-bba36ed503fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen01 = \"business-person.png\" #\"img/Peoples.jpg\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd357da-ed5e-44ca-b499-b9f6b5f1f75f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(imagen01)\n\u001b[1;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)  \u001b[38;5;66;03m# Sin conversión BGR a RGB\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Ocultar los ejes\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(imagen01)\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)  # Sin conversión BGR a RGB\n",
    "plt.axis(\"off\")  # Ocultar los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f33a51-79f9-4ba7-91bd-ef0d744e04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"business-person.png\")\n",
    "\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#plt.imshow(img)  # Sin conversión BGR a RGB\n",
    "#plt.axis(\"off\")  # Ocultar los ejes\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf63f9f-5e30-4657-9083-8621247673a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STEP 2: Create an FaceLandmarker object.\n",
    "model_asset_path='face_landmarker_v2_with_blendshapes.task'\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path)\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986fe946-bb33-4188-9aaf-72393926fff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(imagen01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7106f8-c9af-4160-800f-a409d60a1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Detect face landmarks from the input image.\n",
    "detection_result = detector.detect(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd26fe1-1abc-46d6-a991-5e840471be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Process the detection result. In this case, visualize it.\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "#cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "#img = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "#img = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(annotated_image)\n",
    "plt.show()\n",
    "\n",
    "#plt.imshow(img)  # Sin conversión BGR a RGB\n",
    "#plt.axis(\"off\")  # Ocultar los ejes\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36559ca3-9ab4-45d4-b553-1133479b861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_face_blendshapes_bar_graph(detection_result.face_blendshapes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f563516-9e82-4b9e-84a4-3b6cf13a0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detection_result.facial_transformation_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a7cf7-7962-4078-bdf5-5adeedf771ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
